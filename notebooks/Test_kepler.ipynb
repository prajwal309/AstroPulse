{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "528a7a16-294f-4d53-bf18-27495afadfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e98329-aa62-4708-8a38-a077b014c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"../data/ZTFBTS/\"  # If unzipped locally\n",
    "data_dir = \"/ocean/projects/phy230064p/shared/kepseismic/BG_Data\" # If running on Bridges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b2242fc-9b9d-4865-bb52-8850e3f876a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import pandas as pd\n",
    "\n",
    "dir_light_curves = f\"{data_dir}/\"\n",
    "\n",
    "def open_light_curve_fits(filename):\n",
    "    \"\"\" Helper function to open a light curve csv file.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(dir_light_curves, filename)\n",
    "    with fits.open(file_path) as data_psd:\n",
    "        df = pd.DataFrame(data_psd[1].data)\n",
    "    return df\n",
    "\n",
    "n_max_obs = 1000\n",
    "\n",
    "# Open all light curves and save as list. Pad observations with zeros up to n_max_obs.\n",
    "mag = np.zeros((len(os.listdir(dir_light_curves)), n_max_obs))\n",
    "time = np.zeros((len(os.listdir(dir_light_curves)), n_max_obs))\n",
    "mask = np.zeros((len(os.listdir(dir_light_curves)), n_max_obs), dtype=bool)\n",
    "\n",
    "idx = 0\n",
    "for filename in os.listdir(dir_light_curves):\n",
    "    if filename.endswith(\".fits\"):\n",
    "        df = open_light_curve_fits(filename)\n",
    "        # If less than n_max_obs observations, pad with zeros\n",
    "        if len(df.iloc[:,0].values) < n_max_obs:\n",
    "            mag[idx, :len(df.iloc[:,0].values)] = df.iloc[:,1].values\n",
    "            time[idx, :len(df.iloc[:,0].values)] = df.iloc[:,0].values\n",
    "            mask[idx, :len(df.iloc[:,0].values)] = 1\n",
    "        # Otherwise, randomly select n_max_obs observations\n",
    "        else:\n",
    "            rand_idx = np.random.choice(len(df.iloc[:,0].values), n_max_obs, replace=False)\n",
    "            mag[idx, :] = df.iloc[:,1].values[rand_idx]\n",
    "            time[idx, :] = df.iloc[:,0].values[rand_idx]\n",
    "            mask[idx, :] = 1\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7572007d-2e43-438d-ae57-2e48feb8217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from models.transformer_utils import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aabadcc-6cfa-45d6-98a5-e8f95a87acd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1121,  0.8055,  0.5262,  ...,  1.2332, -1.4972,  0.4320],\n",
       "         [ 1.8725,  0.2912,  1.1283,  ...,  0.1330, -0.8512, -1.6398],\n",
       "         [ 0.0586,  0.4806,  0.0308,  ..., -1.3632,  0.5167, -0.4511],\n",
       "         ...,\n",
       "         [-0.1214, -0.3452,  0.5496,  ..., -0.2248, -1.2256,  1.2711],\n",
       "         [ 0.3644,  1.1173,  1.9463,  ...,  1.0722,  0.2955, -0.6599],\n",
       "         [ 0.4382,  1.1305, -0.2090,  ...,  0.5223, -0.6597, -1.6678]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Transformer from torch.nn\n",
    "# encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "# transformer = nn.TransformerEncoder(encoder_layer, num_layers=6,)\n",
    "\n",
    "# Our transformer from models/transformer_utiles.py\n",
    "transformer = Transformer(emb=128, heads=2, depth=2, ff_hidden_mult=4)  # Instantiate\n",
    "\n",
    "# Dummy inputs\n",
    "mask_test = torch.ones((1, 100), dtype=torch.bool)\n",
    "x = torch.randn((1, 100, 128))\n",
    "\n",
    "# Forward pass\n",
    "transformer(x, mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "487a5364-8f45-4c33-9bec-c9b7c3ef493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimePositionalEncoding(nn.Module):\n",
    "    \"\"\" Time encodings for Transformer. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_emb):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            d_emb - Dimensionality when projecting to the fourier feature basis.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.d_emb = d_emb\n",
    "\n",
    "    def forward(self, t):\n",
    "        pe = torch.zeros(t.shape[0], t.shape[1], self.d_emb).to(t.device)  # (B, T, D)\n",
    "        div_term = torch.exp(torch.arange(0, self.d_emb, 2).float() * (-math.log(10000.0) / self.d_emb))[None, None, :].to(t.device)  # (1, 1, D / 2)\n",
    "        t = t.unsqueeze(2)  # (B, 1, T)\n",
    "        pe[:, :, 0::2] = torch.sin(t * div_term)  # (B, T, D / 2)\n",
    "        pe[:, :, 1::2] = torch.cos(t * div_term)  # (B, T, D / 2)\n",
    "        return pe  # (B, T, D)\n",
    "\n",
    "class TransformerWithTimeEmbeddings(nn.Module):\n",
    "    \"\"\" Transformer encoer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_out=1, **kwargs):\n",
    "        \"\"\"\n",
    "        :param n_out: Number of outputs per sequence element (e.g., number of bands).\n",
    "        :param kwargs: Transformer arguments.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_mag = nn.Linear(in_features=1, out_features=kwargs['emb'])\n",
    "        self.embedding_t = TimePositionalEncoding(kwargs['emb'])\n",
    "        self.transformer = Transformer(**kwargs)\n",
    "        self.projection = nn.Linear(in_features=kwargs['emb'], out_features=n_out)\n",
    "\n",
    "    def forward(self, x, t, mask=None):\n",
    "        \"\"\"\n",
    "        :param x: Input sequence (B, T, 1).\n",
    "        :param t: Time sequence (B, T).\n",
    "        :param mask: Padding mask (B, T).\n",
    "        :return: Output sequence (B, T, n_out).\n",
    "        \"\"\"\n",
    "        t = t - t[:, 0].unsqueeze(1)  # (B, T)  # Relative time\n",
    "        t_emb = self.embedding_t(t)  # (B, T, D)  # Project to embedding dimension of transformer\n",
    "        x = self.embedding_mag(x) + t_emb  # (B, T, D)  # Add time embeddings to magnitude embeddings\n",
    "        x = self.transformer(x, mask)  # (B, T, D)  # Transformer\n",
    "        x = self.projection(x)  # (B, T, n_out)  # Project each sequence element (independently) to output dim\n",
    "\n",
    "        return x\n",
    "\n",
    "transformer = TransformerWithTimeEmbeddings(n_out=1, emb=128, heads=2, depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abbf213c-af20-43a9-9358-321ba4a4e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch tensors\n",
    "mag = torch.Tensor(mag)\n",
    "time = torch.Tensor(time)\n",
    "mask = torch.Tensor(mask).to(torch.bool)\n",
    "\n",
    "# Standardize mag\n",
    "mag_mean = mag.mean()\n",
    "mag_std = mag.std()\n",
    "mag = (mag - mag_mean) / mag_std\n",
    "\n",
    "# # Standardize time # Don't standardize time, since we'll zero-subtract for simplicity\n",
    "# time_mean = time.mean()\n",
    "# time_std = time.std()\n",
    "# time = (time - time_mean) / time_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf0b1ba2-278c-4bb5-a3c4-26cefe84b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience function to get random masks\n",
    "\n",
    "def get_random_mask(padding_mask, f_mask=0.15):\n",
    "    \"\"\" Get a random contiguous masks for the input sequence.\n",
    "    :param padding_mask: Padding mask (B, T).\n",
    "    :param f_mask: Fraction of mask to keep.\n",
    "    :return: Mask (B, T).\n",
    "    \"\"\"\n",
    "    mask = torch.ones_like(padding_mask)\n",
    "    mask_pred = torch.ones_like(padding_mask)\n",
    "    for i in range(padding_mask.shape[0]):\n",
    "        n_obs = padding_mask[i].sum().item()\n",
    "        n_obs_to_keep = int(n_obs * f_mask)\n",
    "        start = torch.randint(0, n_obs - n_obs_to_keep + 1, (1,)).item()\n",
    "        end = start + n_obs_to_keep\n",
    "\n",
    "        # Mask containing observations to be kept\n",
    "        mask[i, start:end] = False  # Mask out observations from start to end\n",
    "        mask[i, n_obs:] = False\n",
    "\n",
    "        # Mask only containing observations to be predicted\n",
    "        mask_pred[i, end:n_obs] = False\n",
    "        mask_pred[i, :start] = False\n",
    "        mask_pred[i, start:end] = True\n",
    "        mask_pred[i, n_obs:] = False\n",
    "        \n",
    "    return mask, mask_pred\n",
    "\n",
    "# Test the mask function\n",
    "\n",
    "f_mask = 0.15\n",
    "mask_test = mask[144:]\n",
    "mask_in, mask_pred = get_random_mask(mask_test, f_mask=f_mask)  # Mask out 15% of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3421c3e6-183c-4dc1-a2e7-d14ae3dce8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABiUAAAB4CAYAAACdO/FpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAANYklEQVR4nO3dXWjW5f/A8c/mdM7c5kO4OdRaEZhpUS7NDDxQspDAjKJYIhZ10CynIUWlHlRaRhE9oNlBddCjB9EDdTAsFpGpzYoezIIKJZvSg209+LRd/4Pfr7vf/f9Z/V16+d98vWDgvtflzfU9+eDtm/t7l6SUUgAAAAAAABxlpcf6AAAAAAAAwPFBlAAAAAAAALIQJQAAAAAAgCxECQAAAAAAIAtRAgAAAAAAyEKUAAAAAAAAshAlAAAAAACALMp68pe6u7tj586dUVlZGSUlJUf6TAAAAAAAQC+SUorOzs6oq6uL0tI//zxEj6LEzp07Y/To0T0+HAAAAAAA0Pfs2LEjRo0a9afrPXp8U2VlZY8PBAAAAAAA9E1/1w96FCU8sgkAAAAAAPjf/q4f+KJrAAAAAAAgC1ECAAAAAADIQpQAAAAAAACyECUAAAAAAIAsRAkAAAAAACALUQIAAAAAAMhClAAAAAAAALIQJQAAAAAAgCxECQAAAAAAIAtRAgAAAAAAyEKUAAAAAAAAshAlAAAAAACALEQJAAAAAAAgC1ECAAAAAADIQpQAAAAAAACyECUAAAAAAIAsRAkAAAAAACALUQIAAAAAAMhClAAAAAAAALIQJQAAAAAAgCxECQAAAAAAIAtRAgAAAAAAyEKUAAAAAAAAshAlAAAAAACALEQJAAAAAAAgC1ECAAAAAADIQpQAAAAAAACyECUAAAAAAIAsRAkAAAAAACALUQIAAAAAAMhClAAAAAAAALIQJQAAAAAAgCxECQAAAAAAIAtRAgAAAAAAyEKUAAAAAAAAshAlAAAAAACALEQJAAAAAAAgC1ECAAAAAADIQpQAAAAAAACyECUAAAAAAIAsRAkAAAAAACALUQIAAAAAAMhClAAAAAAAALIQJQAAAAAAgCxECQAAAAAAIAtRAgAAAAAAyEKUAAAAAAAAshAlAAAAAACALEQJAAAAAAAgC1ECAAAAAADIQpQAAAAAAACyECUAAAAAAIAsRAkAAAAAACALUQIAAAAAAMhClAAAAAAAALIQJQAAAAAAgCxECQAAAAAAIAtRAgAAAAAAyEKUAAAAAAAAshAlAAAAAACALEQJAAAAAAAgC1ECAAAAAADIQpQAAAAAAACyECUAAAAAAIAsRAkAAAAAACALUQIAAAAAAMhClAAAAAAAALIQJQAAAAAAgCxECQAAAAAAIAtRAgAAAAAAyEKUAAAAAAAAshAlAAAAAACALEQJAAAAAAAgix5FiZTSkT4HAAAAAADQy/1dP+hRlPj+++97dBgAAAAAAKDv6uzs/Mv1sp686LBhwyIiYvv27VFdXd2TlwD4f6WjoyNGjx4dO3bsiKqqqmN9HIB/zFwD+hpzDehrzDWgr0kpRWdnZ9TV1f3lvh5FidLSf33Aorq62tAE+pSqqipzDehTzDWgrzHXgL7GXAP6kv/Lhxh80TUAAAAAAJCFKAEAAAAAAGTRoyhRXl4ey5cvj/Ly8iN9HoBjwlwD+hpzDehrzDWgrzHXgONVSUopHetDAAAAAAAAfZ/HNwEAAAAAAFmIEgAAAAAAQBaiBAAAAAAAkIUoAQAAAAAAZCFKAAAAAAAAWfQoSjz66KNx8sknx8CBA2Py5MmxadOmI30ugH9s5cqVce6550ZlZWWMGDEiZs+eHdu2bSvas3fv3mhqaorhw4fH4MGD47LLLotdu3YV7dm+fXvMmjUrBg0aFCNGjIglS5bEwYMHc94KwCHdc889UVJSEs3NzYVr5hrQ23zzzTdx9dVXx/Dhw6OioiImTJgQ7733XmE9pRTLli2LkSNHRkVFRcyYMSO++OKLotf44YcforGxMaqqqmLIkCFx7bXXxs8//5z7VgCiq6srli5dGvX19VFRURGnnnpq3HnnnZFSKuwx14Dj3WFHieeffz4WL14cy5cvjy1btsRZZ50VM2fOjN27dx+N8wH0WGtrazQ1NcW7774bLS0tceDAgbjwwgvjl19+KexZtGhRvPLKK7Fu3bpobW2NnTt3xpw5cwrrXV1dMWvWrNi/f3+888478dRTT8WTTz4Zy5YtOxa3BFCwefPmeOyxx+LMM88sum6uAb3Jjz/+GFOnTo3+/fvH66+/Hp9++mncf//9MXTo0MKeVatWxUMPPRRr1qyJjRs3xgknnBAzZ86MvXv3FvY0NjbGJ598Ei0tLfHqq6/GW2+9Fddff/2xuCXgOHfvvffG6tWr45FHHomtW7fGvffeG6tWrYqHH364sMdcA4576TBNmjQpNTU1FX7v6upKdXV1aeXKlYf7UgBZ7d69O0VEam1tTSmltGfPntS/f/+0bt26wp6tW7emiEgbNmxIKaX02muvpdLS0tTe3l7Ys3r16lRVVZX27duX9wYA/q2zszOddtppqaWlJU2bNi0tXLgwpWSuAb3PLbfcki644II/Xe/u7k61tbXpvvvuK1zbs2dPKi8vT88++2xKKaVPP/00RUTavHlzYc/rr7+eSkpK0jfffHP0Dg9wCLNmzUrXXHNN0bU5c+akxsbGlJK5BpBSSof1SYn9+/dHW1tbzJgxo3CttLQ0ZsyYERs2bDiSrQTgiPvpp58iImLYsGEREdHW1hYHDhwommljx46NMWPGFGbahg0bYsKECVFTU1PYM3PmzOjo6IhPPvkk4+kB/tDU1BSzZs0qml8R5hrQ+7z88svR0NAQl19+eYwYMSLOPvvsePzxxwvrX331VbS3txfNterq6pg8eXLRXBsyZEg0NDQU9syYMSNKS0tj48aN+W4GICLOP//8WL9+fXz++ecREfHhhx/G22+/HRdffHFEmGsAERFlh7P5u+++i66urqI3sRERNTU18dlnnx3RgwEcSd3d3dHc3BxTp06N8ePHR0REe3t7DBgwIIYMGVK0t6amJtrb2wt7DjXzfl8DyO25556LLVu2xObNm/9rzVwDepsvv/wyVq9eHYsXL47bbrstNm/eHDfddFMMGDAg5s2bV5hLh5pb/znXRowYUbReVlYWw4YNM9eA7G699dbo6OiIsWPHRr9+/aKrqyvuvvvuaGxsjIgw1wDiMKMEQG/V1NQUH3/8cbz99tvH+igAPbZjx45YuHBhtLS0xMCBA4/1cQD+se7u7mhoaIgVK1ZERMTZZ58dH3/8caxZsybmzZt3jE8HcPheeOGFePrpp+OZZ56JM844Iz744INobm6Ouro6cw3g3w7r8U0nnnhi9OvXL3bt2lV0fdeuXVFbW3tEDwZwpCxYsCBeffXVePPNN2PUqFGF67W1tbF///7Ys2dP0f7/nGm1tbWHnHm/rwHk1NbWFrt3745zzjknysrKoqysLFpbW+Ohhx6KsrKyqKmpMdeAXmXkyJExbty4omunn356bN++PSL+mEt/9R60trY2du/eXbR+8ODB+OGHH8w1ILslS5bErbfeGldeeWVMmDAh5s6dG4sWLYqVK1dGhLkGEHGYUWLAgAExceLEWL9+feFad3d3rF+/PqZMmXLEDwfwT6SUYsGCBfHiiy/GG2+8EfX19UXrEydOjP79+xfNtG3btsX27dsLM23KlCnx0UcfFf2DsKWlJaqqqv7rDTTA0TZ9+vT46KOP4oMPPij8NDQ0RGNjY+HP5hrQm0ydOjW2bdtWdO3zzz+Pk046KSIi6uvro7a2tmiudXR0xMaNG4vm2p49e6Ktra2w54033oju7u6YPHlyhrsA+MOvv/4apaXF/93Wr1+/6O7ujghzDSCiB49vWrx4ccybNy8aGhpi0qRJ8eCDD8Yvv/wS8+fPPxrnA+ixpqameOaZZ+Kll16KysrKwrM3q6uro6KiIqqrq+Paa6+NxYsXx7Bhw6KqqipuvPHGmDJlSpx33nkREXHhhRfGuHHjYu7cubFq1apob2+PO+64I5qamqK8vPxY3h5wHKqsrCx8L87vTjjhhBg+fHjhurkG9CaLFi2K888/P1asWBFXXHFFbNq0KdauXRtr166NiIiSkpJobm6Ou+66K0477bSor6+PpUuXRl1dXcyePTsi/vXJiosuuiiuu+66WLNmTRw4cCAWLFgQV155ZdTV1R3DuwOOR5dcckncfffdMWbMmDjjjDPi/fffjwceeCCuueaaiDDXACIiIvXAww8/nMaMGZMGDBiQJk2alN59992evAzAURURh/x54oknCnt+++23dMMNN6ShQ4emQYMGpUsvvTR9++23Ra/z9ddfp4svvjhVVFSkE088Md18883pwIEDme8G4NCmTZuWFi5cWPjdXAN6m1deeSWNHz8+lZeXp7Fjx6a1a9cWrXd3d6elS5emmpqaVF5enqZPn562bdtWtOf7779PV111VRo8eHCqqqpK8+fPT52dnTlvAyCllFJHR0dauHBhGjNmTBo4cGA65ZRT0u2335727dtX2GOuAce7kpRSOpZRBAAAAAAAOD4c1ndKAAAAAAAA9JQoAQAAAAAAZCFKAAAAAAAAWYgSAAAAAABAFqIEAAAAAACQhSgBAAAAAABkIUoAAAAAAABZiBIAAAAAAEAWogQAAAAAAJCFKAEAAAAAAGQhSgAAAAAAAFn8DxZCf821mzfhAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2000x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask in: original mask with 0.15 of observations masked out\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask pred: observations to be predicted\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to plot a mask\n",
    "def plot_mask(mask):\n",
    "    \"\"\" `mask` is a 1D boolean array.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 1))\n",
    "    plt.imshow(mask[None, :], aspect='auto', cmap='binary', vmin=0, vmax=1)\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "print(\"Mask\")\n",
    "plot_mask(mask_test[0].detach().numpy())\n",
    "\n",
    "print(f\"Mask in: original mask with {f_mask} of observations masked out\")\n",
    "plot_mask(mask_in[0].detach().numpy())\n",
    "\n",
    "print(\"Mask pred: observations to be predicted\")\n",
    "plot_mask(mask_pred[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5fb5b7b-ce80-4ffa-82b7-02c327815a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1000, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_small_batch = 4\n",
    "\n",
    "out = transformer(mag[:n_small_batch].unsqueeze(-1), time[:n_small_batch], mask[:n_small_batch])  # Unsqueeze just adds a channel dimension (B, T, 1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "260a256c-cfbb-4222-a548-3c2b52703a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLightCurveEncoder(pl.LightningModule):\n",
    "    def __init__(self, f_mask=0.2, transformer_kwargs={\"n_out\":1, \"emb\":128, \"heads\":2, \"depth\":4}, optimizer_kwargs={}, lr=1e-3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.optimizer_kwargs = optimizer_kwargs\n",
    "        self.lr = lr\n",
    "        self.f_mask = f_mask\n",
    "\n",
    "        self.net = TransformerWithTimeEmbeddings(**transformer_kwargs)\n",
    "\n",
    "    def forward(self, x, t, mask=None):\n",
    "        x = x[..., None]\n",
    "        x = self.net(x, t, mask)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.RAdam(self.parameters(), lr=self.lr, **self.optimizer_kwargs)\n",
    "        return {\"optimizer\": optimizer}\n",
    "\n",
    "    def masked_pred(self, x, t, padding_mask, f_mask=0.15):\n",
    "        # Get random mask and predict with masked inputs; then, return only the unmasked outputs\n",
    "        mask_in, mask_pred = get_random_mask(padding_mask, f_mask=f_mask)\n",
    "        x_masked = x.clone()\n",
    "        x_masked[~mask_in] = 0\n",
    "        x_pred = self(x_masked, t, mask=padding_mask)[..., 0]  \n",
    "        return x[mask_pred], x_pred[mask_pred]\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, t, padding_mask = batch\n",
    "        x, x_pred = self.masked_pred(x, t, padding_mask, f_mask=self.f_mask)\n",
    "        loss = nn.MSELoss()(x, x_pred)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, on_step=False, prog_bar=True,)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, t, padding_mask = batch\n",
    "        x, x_pred = self.masked_pred(x, t, padding_mask, f_mask=self.f_mask)\n",
    "        loss = nn.MSELoss()(x, x_pred)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, on_step=False, prog_bar=True,)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61cf9172-5e8e-47c7-adbd-045f475a3b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlce = MaskedLightCurveEncoder(f_mask=0.15, lr=6e-4, transformer_kwargs={\"n_out\":1, \"emb\":256, \"heads\":4, \"depth\":12, \"dropout\":0.02})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3019226-3c2d-428a-a9e8-931342ad7df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "val_fraction = 0.05\n",
    "batch_size = 64\n",
    "n_samples_val = int(val_fraction * mag.shape[0])\n",
    "\n",
    "dataset = TensorDataset(mag, time, mask)\n",
    "\n",
    "dataset_train, dataset_val = random_split(dataset, [mag.shape[0] - n_samples_val, n_samples_val])\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, num_workers=8, pin_memory=True, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=batch_size, num_workers=8, pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc6c8c-86a1-4456-90a4-c70fb7903c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/jet/home/schen15/.local/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /jet/home/schen15/lightning_logs/version_21769829/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type                          | Params\n",
      "-------------------------------------------------------\n",
      "0 | net  | TransformerWithTimeEmbeddings | 9.5 M \n",
      "-------------------------------------------------------\n",
      "9.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.5 M     Total params\n",
      "37.875    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/schen15/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, v_num=2.18e+7]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  2.57it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 15/15 [00:12<00:00,  1.19it/s, v_num=2.18e+7, val_loss=0.759, train_loss=1.120]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, v_num=2.18e+7, val_loss=0.748, train_loss=1.040]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, v_num=2.18e+7, val_loss=0.771, train_loss=1.030]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, v_num=2.18e+7, val_loss=0.771, train_loss=1.030]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\u001b[A\n",
      "Epoch 5:  47%|████▋     | 7/15 [00:05<00:06,  1.19it/s, v_num=2.18e+7, val_loss=0.764, train_loss=1.030] "
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=100, accelerator='gpu',)\n",
    "trainer.fit(model=mlce, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81438769-7eb9-4c06-b87f-69c55031b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlce = mlce.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a53f364-b930-45d7-9d0c-78ada2fe3f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_test, time_test, mask_test = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25651879-2003-4104-b641-f2c33325173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 2, figsize=(12, 12))\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(2):\n",
    "        ii = i * 2 + j\n",
    "\n",
    "        fill_min, fill_max = 2, 7  # Mask out observations from fill_min to fill_max\n",
    "        mask_tofill = mask_test[ii:ii + 1].clone()\n",
    "        mask_tofill[:, fill_min:fill_max + 1] = False\n",
    "\n",
    "        # Remove zero-padded, masked out elements\n",
    "        mag_truth = mag_test[ii:ii + 1].clone()[mask_test[ii:ii + 1]]\n",
    "        mag_test_in = mag_test[ii:ii + 1].clone()[mask_test[ii:ii + 1]]\n",
    "        time_test_in = time_test[ii:ii + 1].clone()[mask_test[ii:ii + 1]]\n",
    "\n",
    "        mag_test_in[fill_min:fill_max + 1] = 0\n",
    "\n",
    "        mag_pred = mlce(mag_test_in[None, ...], time_test_in[None, ...],)[0, :, 0].detach().numpy()[fill_min:fill_max + 1]\n",
    "\n",
    "        ax[i, j].scatter(time_test_in[fill_min:fill_max + 1], mag_pred, label='pred')\n",
    "        ax[i, j].scatter(time_test_in, mag_truth, label='truth')\n",
    "\n",
    "        # Mark the masked observations; if fill_[min/max] is bigger than the number of observations, make it the length of the observations\n",
    "        fill_min = min(fill_min, len(time_test_in) - 1)\n",
    "        fill_max = min(fill_max, len(time_test_in) - 1)\n",
    "        \n",
    "        ax[i, j].axvspan(time_test_in[fill_min], time_test_in[fill_max], alpha=0.1, color='red', label='masked')\n",
    "        ax[i, j].legend()\n",
    "\n",
    "        ax[i, j].set_xlabel('time')\n",
    "        ax[i, j].set_ylabel('mag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c1165e-f1ef-48db-ac76-ad55098ede4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NGC PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
